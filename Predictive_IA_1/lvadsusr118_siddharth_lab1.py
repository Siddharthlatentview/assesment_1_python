# -*- coding: utf-8 -*-
"""LVADSUSR118_siddharth_lab1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17n2zJsCdnyK7Y6s7At3vTLNVqjJUHDFT
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score,mean_squared_error
from sklearn.preprocessing import LabelEncoder

df=pd.read_csv('expenses.csv')

df.describe()

df.info()
df.dropna()
df.drop_duplicates()

sns.boxplot(df)

sns.scatterplot(df['charges'])

label_encoder = LabelEncoder()

df['sex']=label_encoder.fit_transform(df['sex'])
df['smoker']=label_encoder.fit_transform(df['smoker'])
df['region']=label_encoder.fit_transform(df['region'])

df.head()

X = df.drop(columns=['charges'])
y = df['charges']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)


model = LinearRegression()
m1=model.fit(X_train, y_train)
y_pred = model.predict(X_test)

r=r2_score(y_test,y_pred)
m=mean_squared_error(y_test,y_pred)
rmse=np.sqrt(m)
print("Mean Squared error is ",m)
print("R-squared value is ",r)
print("RMSE is ",rmse)

# Mean squared error is found out by finding the difference bewteen actual and predicted value. The difference is squared and their mean is taken.
# Gradient descent can be used to reduce the error. We take small steps in order to move towards minimal loss. We take a fixed learning rate value and make small changes.
# derivatives and partitail derviative from slope can be used to measure rate of change.
# we can use the linear regression model to find out the charges of a patient based on conditions like age, sex, smoker etc.
# This can help us in finding the expense likely to be incurred.